{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66e7bd8",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826adc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Pandas for data manipulation and analysis\n",
    "import csv  # CSV module for reading and writing CSV files\n",
    "from collections import ChainMap  # ChainMap for creating a single view of multiple mappings\n",
    "import json  # JSON module for working with JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9f40ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open and read a JSON Lines file into a list of dictionaries\n",
    "with open('nq-train-07.jsonl') as json_file:      \n",
    "    data = json_file.readlines() # Read lines from the file and store them in a list\n",
    "    data = list(map(json.loads, data)) # Parse each line as JSON and create a list of dictionaries\n",
    "df = pd.DataFrame(data) # Create a Pandas DataFrame from the list of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd3d97",
   "metadata": {},
   "source": [
    "Initialize empty dictionaries to store start and end tokens, and a list for indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ac72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = {}  # Dictionary to store start tokens\n",
    "end = {}    # Dictionary to store end tokens\n",
    "index = []  # List to store indices\n",
    "# Iterate through each row in the DataFrame\n",
    "for i in range(len(df)):\n",
    "    # Check if 'short_answers' is present in the annotations for the current row\n",
    "    if df['annotations'][i][0]['short_answers']:\n",
    "        index.append(i)  # Append the index to the list\n",
    "        start[i] = df['annotations'][i][0]['short_answers'][0]['start_token']  # Store the start token\n",
    "        end[i] = df['annotations'][i][0]['short_answers'][0]['end_token']  # Store the end token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132893e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = {} # Initialize an empty dictionary to store answers\n",
    "# Iterate through the indices stored in the 'index' list\n",
    "for i in index:\n",
    "    res = '' # Initialize an empty string to concatenate tokens\n",
    "    # Iterate through the tokens within the specified range [start[i]: end[i]]\n",
    "    for j in range(len(df['document_tokens'][i][start[i]: end[i]])):\n",
    "        res += ' ' + df['document_tokens'][i][start[i]: end[i]][j]['token'] # Concatenate each token to the result string\n",
    "    ans[i] = res # Store the concatenated result as the answer for the corresponding index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d007e7",
   "metadata": {},
   "source": [
    "Create a new DataFrame from the 'ans' dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1b0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dictionary = pd.DataFrame(ans.values(), index = ans.keys(), columns = ['answer']) # The values in 'ans' serve as the data, index as row labels, and 'answer' as the column label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd25aad",
   "metadata": {},
   "source": [
    "Merge the original DataFrame 'df' with the DataFrame 'df_dictionary' using the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72313151",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.merge(df, df_dictionary, left_index=True, right_index=True) # Left_index and right_index are set to True to perform the merge based on the indices\n",
    "fdf = fdf[['question_text', 'question_tokens', 'answer']] # Select specific columns ('question_text', 'question_tokens', 'answer') in the merged DataFrame\n",
    "fdf.to_csv('NQ_Dataset/filename') #Save the resulting DataFrame to a CSV file named 'filename.csv' in the 'NQ_Dataset' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9bb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
